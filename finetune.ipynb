{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_pretrain import BertModel, BertTokenizer\n",
    "from pytorch_pretrain import BertAdam\n",
    "from bert_encoder import TokenEncode\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "path = os.listdir('./data/jy/jy/')\n",
    "path_li = ['./data/jy/jy/'+i for i in path if 'json' in i]\n",
    "def get_other_text(word):\n",
    "    total_cnt = len(word.strip())\n",
    "    cn_cnt = 0\n",
    "    en_cnt = 0\n",
    "    num_cnt = 0\n",
    "    symbols_cnt = 0\n",
    "    other_cnt = 0\n",
    "    for ch in word:\n",
    "        if '\\u4e00' <= ch <= '\\u9fff':\n",
    "            cn_cnt = cn_cnt + 1\n",
    "        elif ('a'<=ch<='z' or 'A'<=ch<='Z'):\n",
    "            en_cnt = en_cnt + 1\n",
    "        elif ch.isdigit():\n",
    "            num_cnt = num_cnt + 1\n",
    "        elif ch in string.punctuation:\n",
    "            symbols_cnt = symbols_cnt + 1\n",
    "        else:\n",
    "            other_cnt = other_cnt + 1\n",
    "    cn_radio = cn_cnt/total_cnt\n",
    "    en_radio = en_cnt/total_cnt\n",
    "    num_radio = num_cnt/total_cnt\n",
    "    symbols_radio = symbols_cnt/total_cnt\n",
    "    other_radio = other_cnt/total_cnt\n",
    "    have_ = 1 if '-' in word else 0\n",
    "    have_mao = 1 if ':' in word else 0\n",
    "    have_yuan = 1 if '元' in word else 0\n",
    "    have_dot = 1 if '.' in word else 0\n",
    "    len_word = len(word)/30\n",
    "    return [cn_radio, en_radio, num_radio, symbols_radio, other_radio, have_, have_mao, have_yuan, have_dot, len_word]\n",
    "\n",
    "def get_one_label(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        di = json.loads(content)\n",
    "        shapes_li = di['shapes']\n",
    "        h = di['imageHeight']\n",
    "        w = di['imageWidth']\n",
    "        li = list()\n",
    "        for i in shapes_li:\n",
    "            points = i['points']\n",
    "            group_id = i['group_id'] if i['group_id'] else 0\n",
    "            text = i['label']\n",
    "            if len(points) == 2:\n",
    "                x1 = points[0][0]/w\n",
    "                y1 = points[0][1]/h\n",
    "                x2 = points[1][0]/w\n",
    "                y2 = points[1][1]/h\n",
    "            else:\n",
    "                x1 = points[0][0]/w\n",
    "                y1 = points[0][1]/h\n",
    "                x2 = points[2][0]/w\n",
    "                y2 = points[2][1]/h\n",
    "            ret_li = get_other_text(text)\n",
    "            li.append([text, x1, y1, x2, y2, group_id, path] + ret_li)\n",
    "        \n",
    "        mx,my = 0,0\n",
    "        total_li = list()\n",
    "        for inner_li1 in li:\n",
    "            x_li, y_li = list(), list()\n",
    "            for inner_li2 in li:\n",
    "                x_ = inner_li1[1] - inner_li2[1]\n",
    "                y_ = inner_li1[2] - inner_li2[2]\n",
    "                x_li.append(x_)\n",
    "                y_li.append(y_)\n",
    "            x_li.sort()\n",
    "            y_li.sort()\n",
    "\n",
    "            zerox = x_li.index(0.0)\n",
    "            zeroy = y_li.index(0.0)\n",
    "\n",
    "            left_x = x_li[zerox-1] if 0 <= zerox-1 <len(x_li) else 0\n",
    "            right_x = x_li[zerox+1] if 0 <= zerox+1 <len(x_li) else 0\n",
    "            left_y = y_li[zeroy-1] if 0 <= zeroy-1 <len(y_li) else 0\n",
    "            right_y = y_li[zeroy+1] if 0 <= zeroy+1 <len(y_li) else 0\n",
    "            x_li = x_li[:18]\n",
    "            y_li = y_li[:18]\n",
    "            total_li.append(inner_li1 + x_li + y_li + [left_x, right_x, left_y, right_y])\n",
    "        return total_li\n",
    "\n",
    "def get_df():\n",
    "    li_total = list()\n",
    "    for p in path_li:\n",
    "        li = get_one_label(p)\n",
    "        li_total.extend(li)\n",
    "    print(len(li_total))\n",
    "    df = pd.DataFrame(li_total)\n",
    "    df.loc[df[5]==4]=3\n",
    "    df.loc[df[5]==14]=4\n",
    "    # print(df[5].value_counts())\n",
    "    return df\n",
    "\n",
    "df = get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = 512\n",
    "BERT_PATH = '../Bert-Chinese-Text-Classification-Pytorch/bert_pretrain/'\n",
    "BATCH_SIZE = 5\n",
    "INPUT_SIZE, OUTPUT_SIZE= 768, 14\n",
    "# 1：物流，2：服务，3：家电\n",
    "LABEL_INDEX = 2\n",
    "LR = 1e-5\n",
    "EPOCH = 8\n",
    "ROUND = 3\n",
    "F1 = 'macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 255/255 [00:00<00:00, 5987.00it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "token_encoder = TokenEncode(BERT_PATH, pad_size)\n",
    "data = [[token_encoder.get_token_mask(str(i[0])), torch.tensor([i[1:5].tolist() + i[7:57].tolist()]).to(device), i[5]] for i in tqdm(df.values)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_order = range(len(data))\n",
    "np.random.shuffle(list(random_order))\n",
    "num = 8\n",
    "train = [data[j] for i, j in enumerate(random_order) if i % num != 0]\n",
    "valid = [data[j] for i, j in enumerate(random_order) if i % num == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data = data\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train)\n",
    "train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=False)\n",
    "valid_dataset = MyDataset(valid)\n",
    "valid_iter = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 54])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_iter))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_PATH).to(device)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.linear1 = torch.nn.Linear(512, 256)\n",
    "        self.linear2 = torch.nn.Linear(54, 128)\n",
    "        self.linear3 = torch.nn.Linear(768+128, 512)\n",
    "        self.linear4 = torch.nn.Linear(256, output_size)\n",
    "    def forward(self, x):\n",
    "        _1, pool1 = self.bert(x[0][0].squeeze(1), None, x[0][1].squeeze(1))\n",
    "        ret = self.linear2(x[1])\n",
    "        # pool2 = self.linear1(pool1)\n",
    "        return self.linear4(self.linear1(self.linear3(torch.cat([pool1, ret.squeeze(1)], dim=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(INPUT_SIZE, OUTPUT_SIZE).to(device)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "loss.to(device)\n",
    "param_optimizer = list(model.named_parameters())\n",
    "# print(param_optimizer)\n",
    "# 以下的层不进行参数的衰减\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "# 其他的层进行参数的衰减\n",
    "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=LR, warmup=0.05, t_total=len(train_iter) * EPOCH)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  [(0, [0.667, 18, 27]), (1, [0.0, 0, 5]), (2, [0.0, 0, 9]), (3, [0.611, 11, 18]), (4, [0.0, 0, 8]), (5, [0.083, 1, 12]), (6, [0.0, 0, 7]), (7, [0.0, 0, 14]), (8, [0.0, 0, 8]), (9, [0.556, 10, 18]), (10, [0.0, 0, 7]), (11, [0.0, 0, 7]), (12, [0.0, 0, 8]), (13, [0.143, 1, 7])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [0.0, 0, 3]), (4, [0.0, 0, 1]), (5, [1.0, 1, 1]), (6, [0.0, 0, 3]), (7, [0.5, 1, 2]), (8, [0.0, 0, 1]), (9, [1.0, 3, 3]), (10, [0.0, 0, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [0.5, 1, 2])]\n",
      "epoch:0 | loss_train:2.376 | loss_valid:1.899 | acc_train: 0.265 | acc_valid: 0.562 | f1_train: 0.109 | f1_valid: 0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MyModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------ 模型保存--f1:0.536\n",
      "train:  [(0, [1.0, 30, 30]), (1, [0.833, 5, 6]), (2, [0.286, 2, 7]), (3, [0.5, 9, 18]), (4, [1.0, 7, 7]), (5, [0.545, 6, 11]), (6, [0.143, 1, 7]), (7, [0.636, 7, 11]), (8, [0.1, 1, 10]), (9, [1.0, 17, 17]), (10, [0.429, 3, 7]), (11, [0.857, 6, 7]), (12, [0.4, 4, 10]), (13, [0.857, 6, 7])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [0.0, 0, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [0.5, 1, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [0.0, 0, 4]), (11, [0.0, 0, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:1 | loss_train:1.317 | loss_valid:1.083 | acc_train: 0.671 | acc_valid: 0.719 | f1_train: 0.621 | f1_valid: 0.666\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ 模型保存--f1:0.666\n",
      "train:  [(0, [1.0, 27, 27]), (1, [1.0, 6, 6]), (2, [0.889, 8, 9]), (3, [0.867, 13, 15]), (4, [1.0, 5, 5]), (5, [0.8, 8, 10]), (6, [0.714, 5, 7]), (7, [1.0, 17, 17]), (8, [0.625, 5, 8]), (9, [0.944, 17, 18]), (10, [1.0, 6, 6]), (11, [0.9, 9, 10]), (12, [0.8, 8, 10]), (13, [0.714, 5, 7])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [1.0, 3, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [1.0, 2, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [1.0, 4, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:2 | loss_train:0.801 | loss_valid:0.718 | acc_train: 0.897 | acc_valid: 1.0 | f1_train: 0.893 | f1_valid: 1.0\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------ 模型保存--f1:1.0\n",
      "train:  [(0, [1.0, 27, 27]), (1, [1.0, 8, 8]), (2, [1.0, 9, 9]), (3, [1.0, 15, 15]), (4, [1.0, 7, 7]), (5, [0.846, 11, 13]), (6, [1.0, 9, 9]), (7, [0.846, 11, 13]), (8, [0.833, 5, 6]), (9, [1.0, 16, 16]), (10, [1.0, 6, 6]), (11, [1.0, 9, 9]), (12, [1.0, 10, 10]), (13, [0.857, 6, 7])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [1.0, 3, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [1.0, 2, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [1.0, 4, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:3 | loss_train:0.488 | loss_valid:0.431 | acc_train: 0.961 | acc_valid: 1.0 | f1_train: 0.961 | f1_valid: 1.0\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "train:  [(0, [1.0, 30, 30]), (1, [1.0, 7, 7]), (2, [1.0, 5, 5]), (3, [1.0, 16, 16]), (4, [1.0, 9, 9]), (5, [1.0, 11, 11]), (6, [0.875, 7, 8]), (7, [1.0, 14, 14]), (8, [1.0, 8, 8]), (9, [1.0, 16, 16]), (10, [1.0, 7, 7]), (11, [1.0, 8, 8]), (12, [1.0, 8, 8]), (13, [0.875, 7, 8])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [1.0, 3, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [1.0, 2, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [1.0, 4, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:4 | loss_train:0.34 | loss_valid:0.301 | acc_train: 0.987 | acc_valid: 1.0 | f1_train: 0.983 | f1_valid: 1.0\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "train:  [(0, [0.963, 26, 27]), (1, [1.0, 7, 7]), (2, [1.0, 10, 10]), (3, [1.0, 14, 14]), (4, [1.0, 10, 10]), (5, [0.923, 12, 13]), (6, [0.875, 7, 8]), (7, [1.0, 13, 13]), (8, [1.0, 6, 6]), (9, [1.0, 15, 15]), (10, [1.0, 7, 7]), (11, [1.0, 10, 10]), (12, [1.0, 9, 9]), (13, [0.833, 5, 6])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [1.0, 3, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [1.0, 2, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [1.0, 4, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:5 | loss_train:0.29 | loss_valid:0.236 | acc_train: 0.974 | acc_valid: 1.0 | f1_train: 0.973 | f1_valid: 1.0\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "train:  [(0, [1.0, 33, 33]), (1, [1.0, 5, 5]), (2, [1.0, 10, 10]), (3, [1.0, 15, 15]), (4, [0.9, 9, 10]), (5, [1.0, 7, 7]), (6, [1.0, 7, 7]), (7, [1.0, 13, 13]), (8, [1.0, 8, 8]), (9, [0.938, 15, 16]), (10, [1.0, 7, 7]), (11, [1.0, 9, 9]), (12, [1.0, 8, 8]), (13, [0.857, 6, 7])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [1.0, 3, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [1.0, 2, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [1.0, 4, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:6 | loss_train:0.205 | loss_valid:0.208 | acc_train: 0.981 | acc_valid: 1.0 | f1_train: 0.979 | f1_valid: 1.0\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "train:  [(0, [0.97, 32, 33]), (1, [1.0, 8, 8]), (2, [1.0, 7, 7]), (3, [1.0, 13, 13]), (4, [1.0, 9, 9]), (5, [0.889, 8, 9]), (6, [1.0, 7, 7]), (7, [0.929, 13, 14]), (8, [1.0, 8, 8]), (9, [1.0, 15, 15]), (10, [1.0, 6, 6]), (11, [1.0, 7, 7]), (12, [1.0, 9, 9]), (13, [0.9, 9, 10])]\n",
      "valid:▮  [(0, [1.0, 7, 7]), (1, [1.0, 3, 3]), (3, [1.0, 3, 3]), (4, [1.0, 1, 1]), (5, [1.0, 1, 1]), (6, [1.0, 3, 3]), (7, [1.0, 2, 2]), (8, [1.0, 1, 1]), (9, [1.0, 3, 3]), (10, [1.0, 4, 4]), (11, [1.0, 1, 1]), (12, [1.0, 1, 1]), (13, [1.0, 2, 2])]\n",
      "epoch:7 | loss_train:0.223 | loss_valid:0.198 | acc_train: 0.974 | acc_valid: 1.0 | f1_train: 0.979 | f1_valid: 1.0\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def get_recall(y_li, y_hat_li, which):\n",
    "    di = defaultdict(list)\n",
    "    for ind, i in enumerate(y_li):\n",
    "        if y_hat_li[ind] == i:\n",
    "            di[i].append(1)\n",
    "        else:\n",
    "            di[i].append(0)\n",
    "    for a,b in di.items():\n",
    "        if len(b) > 0:\n",
    "            di[a] = [round(sum(b)/len(b), ROUND), sum(b), len(b)]\n",
    "    dis = sorted(di.items(), key=lambda x:x[0], reverse=False)\n",
    "    print(which, dis)\n",
    "    \n",
    "def my_evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    y_li, y_hat_li, loss_li = list(), list(), list()\n",
    "    for ind, x in enumerate(val_loader):\n",
    "        y_hat = model(x)\n",
    "        los = loss(y_hat.to(device), x[LABEL_INDEX].to(device))\n",
    "        loss_li.append(los.item())\n",
    "        y_hat_li.extend(np.argmax(y_hat.cpu().detach().numpy(), 1).tolist())\n",
    "        y_li.extend(x[LABEL_INDEX].tolist())\n",
    "    f1_eval = f1_score(y_li, y_hat_li, average=F1)\n",
    "    acc = accuracy_score(y_li, y_hat_li)\n",
    "    get_recall(y_li, y_hat_li, 'valid:▮ ')\n",
    "    return round(f1_eval, ROUND), round(np.mean(loss_li), ROUND), round(acc, ROUND)\n",
    "\n",
    "def train():\n",
    "    f1_max = 0\n",
    "    for e in range(EPOCH):\n",
    "        model.train()\n",
    "        y_hat_li, y_li, loss_li = list(), list(), list()\n",
    "        for ind, x in enumerate(train_iter):\n",
    "            model.train()\n",
    "            y_hat = model(x)\n",
    "            y_hat_li.extend(np.argmax(y_hat.cpu().detach().numpy(),1).tolist())\n",
    "            y_li.extend(x[LABEL_INDEX].tolist())\n",
    "            los = loss(y_hat.to(device),  x[LABEL_INDEX].to(device))\n",
    "            optimizer.zero_grad()\n",
    "            los.backward()\n",
    "            optimizer.step()\n",
    "            loss_li.append(los.item())\n",
    "            if ind % 30 == 0 and ind != 0:\n",
    "                f1_train = round(f1_score(y_li, y_hat_li, average=F1), ROUND)\n",
    "                acc_train = round(accuracy_score(y_li, y_hat_li), ROUND)\n",
    "                get_recall(y_li, y_hat_li, 'train: ')\n",
    "                f1_valid, loss_valid, acc_valid = my_evaluate(model, valid_iter)\n",
    "                line_str = 'epoch:{} | loss_train:{} | loss_valid:{} | acc_train: {} | acc_valid: {} | f1_train: {} | f1_valid: {}'\n",
    "                print(line_str.format(e, round(np.mean(loss_li), ROUND), loss_valid, acc_train, acc_valid, f1_train, f1_valid))\n",
    "                y_hat_li, y_li, loss_li = list(), list(), list()\n",
    "                if f1_valid > f1_max:\n",
    "                    torch.save(model, './model/model.pkl')\n",
    "                    f1_max = f1_valid\n",
    "                    print('-'*150, '模型保存--f1:{}'.format(f1_max))\n",
    "                else:\n",
    "                    print('-'*130)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
